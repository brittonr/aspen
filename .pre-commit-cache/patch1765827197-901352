diff --git a/.config/nextest.toml b/.config/nextest.toml
index 839f398..2f4a737 100644
--- a/.config/nextest.toml
+++ b/.config/nextest.toml
@@ -4,3 +4,17 @@ fail-fast = true
 test-threads = 1
 # Increased timeout to 60s for chaos tests that simulate network delays and leader elections
 slow-timeout = { period = "60s", terminate-after = 1 }
+
+# Profile for long-running property-based tests
+[profile.ci]
+retries = 1
+fail-fast = false
+test-threads = 1
+# Extended timeout for property-based tests that run multiple iterations
+slow-timeout = { period = "120s", terminate-after = 1 }
+
+# Specific overrides for known long-running tests
+[[profile.default.overrides]]
+filter = "test(test_proptest_linearizability) | test(test_proptest_fault_recovery)"
+retries = 1
+slow-timeout = { period = "120s", terminate-after = 1 }
diff --git a/src/raft/storage_sqlite.rs b/src/raft/storage_sqlite.rs
index 9527089..958b677 100644
--- a/src/raft/storage_sqlite.rs
+++ b/src/raft/storage_sqlite.rs
@@ -55,6 +55,7 @@ use r2d2_sqlite::SqliteConnectionManager;
 use rusqlite::{Connection, OptionalExtension, params};
 use serde::{Deserialize, Serialize};
 use snafu::{ResultExt, Snafu};
+use tokio::task::JoinError;
 
 use crate::raft::constants::{
     DEFAULT_READ_POOL_SIZE, MAX_BATCH_SIZE, MAX_SETMULTI_KEYS, MAX_SNAPSHOT_ENTRIES,
@@ -212,6 +213,11 @@ pub struct SqliteStateMachine {
     snapshot_idx: Arc<AtomicU64>,
 }
 
+/// Convert a JoinError from spawn_blocking into an io::Error.
+fn join_error_to_io(err: JoinError, operation: &'static str) -> io::Error {
+    io::Error::other(format!("{operation} task failed: {err}"))
+}
+
 /// Apply a batch of buffered entries in a single SQLite transaction.
 ///
 /// This is the core optimization: instead of one transaction per entry,
@@ -1129,146 +1135,152 @@ impl SqliteStateMachine {
 
 impl RaftSnapshotBuilder<AppTypeConfig> for Arc<SqliteStateMachine> {
     async fn build_snapshot(&mut self) -> Result<Snapshot<AppTypeConfig>, io::Error> {
-        // Use read pool connection for snapshot build (non-blocking for writes)
-        let conn = self.read_pool.get().context(PoolSnafu)?;
-        SqliteStateMachine::reset_read_connection(&conn)?;
+        let state = Arc::clone(self);
+        tokio::task::spawn_blocking(move || {
+            // Use read pool connection for snapshot build (non-blocking for writes)
+            let conn = state.read_pool.get().context(PoolSnafu)?;
+            SqliteStateMachine::reset_read_connection(&conn)?;
 
-        // Read all KV data
-        let mut stmt = conn
-            .prepare("SELECT key, value FROM state_machine_kv")
-            .context(QuerySnafu)?;
-        let rows = stmt
-            .query_map([], |row| {
-                Ok((row.get::<_, String>(0)?, row.get::<_, String>(1)?))
-            })
-            .context(QuerySnafu)?;
+            // Read all KV data
+            let mut stmt = conn
+                .prepare("SELECT key, value FROM state_machine_kv")
+                .context(QuerySnafu)?;
+            let rows = stmt
+                .query_map([], |row| {
+                    Ok((row.get::<_, String>(0)?, row.get::<_, String>(1)?))
+                })
+                .context(QuerySnafu)?;
 
-        let mut data = BTreeMap::new();
-        let mut entry_count: u32 = 0;
-        for row in rows {
-            let (key, value) = row.context(QuerySnafu)?;
+            let mut data = BTreeMap::new();
+            let mut entry_count: u32 = 0;
+            for row in rows {
+                let (key, value) = row.context(QuerySnafu)?;
+
+                // Tiger Style: Check entry count BEFORE inserting to prevent unbounded growth
+                entry_count += 1;
+                if entry_count > MAX_SNAPSHOT_ENTRIES {
+                    return Err(io::Error::new(
+                        io::ErrorKind::InvalidInput,
+                        format!(
+                            "snapshot exceeds maximum entry count of {} (current: {})",
+                            MAX_SNAPSHOT_ENTRIES, entry_count
+                        ),
+                    ));
+                }
 
-            // Tiger Style: Check entry count BEFORE inserting to prevent unbounded growth
-            entry_count += 1;
-            if entry_count > MAX_SNAPSHOT_ENTRIES {
+                data.insert(key, value);
+            }
+
+            drop(stmt); // Release statement
+
+            // Read metadata
+            let last_applied_log: Option<openraft::LogId<AppTypeConfig>> = {
+                let bytes: Option<Vec<u8>> = conn
+                    .query_row(
+                        "SELECT value FROM state_machine_meta WHERE key = ?1",
+                        params!["last_applied_log"],
+                        |row| row.get(0),
+                    )
+                    .optional()
+                    .context(QuerySnafu)?;
+
+                match bytes {
+                    Some(bytes) => {
+                        let data: Option<openraft::LogId<AppTypeConfig>> =
+                            bincode::deserialize(&bytes).context(DeserializeSnafu)?;
+                        data
+                    }
+                    None => None,
+                }
+            };
+
+            let last_membership: StoredMembership<AppTypeConfig> = {
+                let bytes: Option<Vec<u8>> = conn
+                    .query_row(
+                        "SELECT value FROM state_machine_meta WHERE key = ?1",
+                        params!["last_membership"],
+                        |row| row.get(0),
+                    )
+                    .optional()
+                    .context(QuerySnafu)?;
+
+                match bytes {
+                    Some(bytes) => bincode::deserialize(&bytes).context(DeserializeSnafu)?,
+                    None => StoredMembership::default(),
+                }
+            };
+
+            drop(conn); // Release connection to pool
+
+            // Serialize snapshot data
+            let snapshot_data = serde_json::to_vec(&data).context(JsonSerializeSnafu)?;
+
+            // Tiger Style: Validate size BEFORE storing to database
+            if snapshot_data.len() as u64 > MAX_SNAPSHOT_SIZE {
                 return Err(io::Error::new(
                     io::ErrorKind::InvalidInput,
                     format!(
-                        "snapshot exceeds maximum entry count of {} (current: {})",
-                        MAX_SNAPSHOT_ENTRIES, entry_count
+                        "serialized snapshot size {} bytes exceeds maximum of {} bytes",
+                        snapshot_data.len(),
+                        MAX_SNAPSHOT_SIZE
                     ),
                 ));
             }
 
-            data.insert(key, value);
-        }
-
-        drop(stmt); // Release statement
-
-        // Read metadata
-        let last_applied_log: Option<openraft::LogId<AppTypeConfig>> = {
-            let bytes: Option<Vec<u8>> = conn
-                .query_row(
-                    "SELECT value FROM state_machine_meta WHERE key = ?1",
-                    params!["last_applied_log"],
-                    |row| row.get(0),
+            // Generate snapshot ID
+            let snapshot_idx = state.snapshot_idx.fetch_add(1, Ordering::Relaxed) + 1;
+            let snapshot_id = if let Some(last) = last_applied_log {
+                format!(
+                    "{}-{}-{snapshot_idx}",
+                    last.committed_leader_id(),
+                    last.index()
                 )
-                .optional()
-                .context(QuerySnafu)?;
-
-            match bytes {
-                Some(bytes) => {
-                    let data: Option<openraft::LogId<AppTypeConfig>> =
-                        bincode::deserialize(&bytes).context(DeserializeSnafu)?;
-                    data
-                }
-                None => None,
-            }
-        };
-
-        let last_membership: StoredMembership<AppTypeConfig> = {
-            let bytes: Option<Vec<u8>> = conn
-                .query_row(
-                    "SELECT value FROM state_machine_meta WHERE key = ?1",
-                    params!["last_membership"],
-                    |row| row.get(0),
+            } else {
+                format!("--{snapshot_idx}")
+            };
+
+            let meta = openraft::SnapshotMeta {
+                last_log_id: last_applied_log,
+                last_membership,
+                snapshot_id: snapshot_id.clone(),
+            };
+
+            // Store snapshot in database (write operation)
+            let snapshot_blob = bincode::serialize(&StoredSnapshot {
+                meta: meta.clone(),
+                data: snapshot_data.clone(),
+            })
+            .context(SerializeSnafu)?;
+
+            let write_conn =
+                state
+                    .write_conn
+                    .lock()
+                    .map_err(|_| SqliteStorageError::MutexPoisoned {
+                        operation: "snapshot_build",
+                    })?;
+
+            // Start transaction with RAII guard for automatic rollback on error
+            // Tiger Style: Atomic snapshot write, fail-fast with explicit error handling
+            let guard = TransactionGuard::new(&write_conn)?;
+
+            write_conn
+                .execute(
+                    "INSERT OR REPLACE INTO snapshots (id, data) VALUES ('current', ?1)",
+                    params![snapshot_blob],
                 )
-                .optional()
-                .context(QuerySnafu)?;
-
-            match bytes {
-                Some(bytes) => bincode::deserialize(&bytes).context(DeserializeSnafu)?,
-                None => StoredMembership::default(),
-            }
-        };
+                .context(ExecuteSnafu)?;
 
-        drop(conn); // Release connection to pool
-
-        // Serialize snapshot data
-        let snapshot_data = serde_json::to_vec(&data).context(JsonSerializeSnafu)?;
-
-        // Tiger Style: Validate size BEFORE storing to database
-        if snapshot_data.len() as u64 > MAX_SNAPSHOT_SIZE {
-            return Err(io::Error::new(
-                io::ErrorKind::InvalidInput,
-                format!(
-                    "serialized snapshot size {} bytes exceeds maximum of {} bytes",
-                    snapshot_data.len(),
-                    MAX_SNAPSHOT_SIZE
-                ),
-            ));
-        }
-
-        // Generate snapshot ID
-        let snapshot_idx = self.snapshot_idx.fetch_add(1, Ordering::Relaxed) + 1;
-        let snapshot_id = if let Some(last) = last_applied_log {
-            format!(
-                "{}-{}-{snapshot_idx}",
-                last.committed_leader_id(),
-                last.index()
-            )
-        } else {
-            format!("--{snapshot_idx}")
-        };
-
-        let meta = openraft::SnapshotMeta {
-            last_log_id: last_applied_log,
-            last_membership,
-            snapshot_id: snapshot_id.clone(),
-        };
+            // Commit transaction - guard is consumed and dropped after commit
+            guard.commit()?;
 
-        // Store snapshot in database (write operation)
-        let snapshot_blob = bincode::serialize(&StoredSnapshot {
-            meta: meta.clone(),
-            data: snapshot_data.clone(),
-        })
-        .context(SerializeSnafu)?;
-
-        let write_conn = self
-            .write_conn
-            .lock()
-            .map_err(|_| SqliteStorageError::MutexPoisoned {
-                operation: "snapshot_build",
-            })?;
-
-        // Start transaction with RAII guard for automatic rollback on error
-        // Tiger Style: Atomic snapshot write, fail-fast with explicit error handling
-        let guard = TransactionGuard::new(&write_conn)?;
-
-        write_conn
-            .execute(
-                "INSERT OR REPLACE INTO snapshots (id, data) VALUES ('current', ?1)",
-                params![snapshot_blob],
-            )
-            .context(ExecuteSnafu)?;
-
-        // Commit transaction - guard is consumed and dropped after commit
-        guard.commit()?;
-
-        Ok(Snapshot {
-            meta,
-            snapshot: Cursor::new(snapshot_data),
+            Ok(Snapshot {
+                meta,
+                snapshot: Cursor::new(snapshot_data),
+            })
         })
+        .await
+        .map_err(|err| join_error_to_io(err, "snapshot_build"))?
     }
 }
 
@@ -1329,13 +1341,25 @@ impl RaftStateMachine<AppTypeConfig> for Arc<SqliteStateMachine> {
 
             // Apply buffer when full to bound memory usage
             if buffer.len() >= BATCH_BUFFER_SIZE {
-                apply_buffered_entries_impl(&self.write_conn, &mut buffer)?;
+                let mut to_apply: Vec<EntryResponder<AppTypeConfig>> = Vec::new();
+                std::mem::swap(&mut to_apply, &mut buffer);
+                let write_conn = Arc::clone(&self.write_conn);
+                tokio::task::spawn_blocking(move || {
+                    apply_buffered_entries_impl(&write_conn, &mut to_apply)
+                })
+                .await
+                .map_err(|err| join_error_to_io(err, "raft_apply_batch"))??;
             }
         }
 
         // Apply remaining entries in buffer
         if !buffer.is_empty() {
-            apply_buffered_entries_impl(&self.write_conn, &mut buffer)?;
+            let write_conn = Arc::clone(&self.write_conn);
+            tokio::task::spawn_blocking(move || {
+                apply_buffered_entries_impl(&write_conn, &mut buffer)
+            })
+            .await
+            .map_err(|err| join_error_to_io(err, "raft_apply_batch"))??;
         }
 
         Ok(())
@@ -1369,67 +1393,75 @@ impl RaftStateMachine<AppTypeConfig> for Arc<SqliteStateMachine> {
         meta: &openraft::SnapshotMeta<AppTypeConfig>,
         mut snapshot: Cursor<Vec<u8>>,
     ) -> Result<(), io::Error> {
-        // Read snapshot data
-        let mut snapshot_data = Vec::new();
-        std::io::copy(&mut snapshot, &mut snapshot_data)
-            .map_err(|err| io::Error::new(io::ErrorKind::InvalidData, err))?;
+        let state = Arc::clone(self);
+        let meta = meta.clone();
+        tokio::task::spawn_blocking(move || {
+            // Read snapshot data
+            let mut snapshot_data = Vec::new();
+            std::io::copy(&mut snapshot, &mut snapshot_data)
+                .map_err(|err| io::Error::new(io::ErrorKind::InvalidData, err))?;
+
+            let new_data: BTreeMap<String, String> =
+                serde_json::from_slice(&snapshot_data).context(JsonDeserializeSnafu)?;
+
+            let conn = state.write_conn.lock().map_err(|_| {
+                io::Error::other(SqliteStorageError::MutexPoisoned {
+                    operation: "snapshot_install",
+                })
+            })?;
 
-        let new_data: BTreeMap<String, String> =
-            serde_json::from_slice(&snapshot_data).context(JsonDeserializeSnafu)?;
+            // Start transaction with RAII guard for automatic rollback on error
+            let guard = TransactionGuard::new(&conn)?;
 
-        let conn = self.write_conn.lock().map_err(|_| {
-            io::Error::other(SqliteStorageError::MutexPoisoned {
-                operation: "snapshot_install",
-            })
-        })?;
+            // Clear existing KV data
+            conn.execute("DELETE FROM state_machine_kv", [])
+                .context(ExecuteSnafu)?;
 
-        // Start transaction with RAII guard for automatic rollback on error
-        let guard = TransactionGuard::new(&conn)?;
+            // Install new data
+            for (key, value) in new_data {
+                conn.execute(
+                    "INSERT INTO state_machine_kv (key, value) VALUES (?1, ?2)",
+                    params![key, value],
+                )
+                .context(ExecuteSnafu)?;
+            }
 
-        // Clear existing KV data
-        conn.execute("DELETE FROM state_machine_kv", [])
+            // Update metadata
+            let last_applied_bytes =
+                bincode::serialize(&meta.last_log_id).context(SerializeSnafu)?;
+            conn.execute(
+                "INSERT OR REPLACE INTO state_machine_meta (key, value) VALUES ('last_applied_log', ?1)",
+                params![last_applied_bytes],
+            )
             .context(ExecuteSnafu)?;
 
-        // Install new data
-        for (key, value) in new_data {
+            let membership_bytes =
+                bincode::serialize(&meta.last_membership).context(SerializeSnafu)?;
             conn.execute(
-                "INSERT INTO state_machine_kv (key, value) VALUES (?1, ?2)",
-                params![key, value],
+                "INSERT OR REPLACE INTO state_machine_meta (key, value) VALUES ('last_membership', ?1)",
+                params![membership_bytes],
             )
             .context(ExecuteSnafu)?;
-        }
 
-        // Update metadata
-        let last_applied_bytes = bincode::serialize(&meta.last_log_id).context(SerializeSnafu)?;
-        conn.execute(
-            "INSERT OR REPLACE INTO state_machine_meta (key, value) VALUES ('last_applied_log', ?1)",
-            params![last_applied_bytes],
-        )
-        .context(ExecuteSnafu)?;
+            // Store snapshot
+            let snapshot_blob = bincode::serialize(&StoredSnapshot {
+                meta: meta.clone(),
+                data: snapshot_data,
+            })
+            .context(SerializeSnafu)?;
+            conn.execute(
+                "INSERT OR REPLACE INTO snapshots (id, data) VALUES ('current', ?1)",
+                params![snapshot_blob],
+            )
+            .context(ExecuteSnafu)?;
 
-        let membership_bytes = bincode::serialize(&meta.last_membership).context(SerializeSnafu)?;
-        conn.execute(
-            "INSERT OR REPLACE INTO state_machine_meta (key, value) VALUES ('last_membership', ?1)",
-            params![membership_bytes],
-        )
-        .context(ExecuteSnafu)?;
+            // Commit transaction - guard is consumed and dropped after commit
+            guard.commit()?;
 
-        // Store snapshot
-        let snapshot_blob = bincode::serialize(&StoredSnapshot {
-            meta: meta.clone(),
-            data: snapshot_data,
+            Ok(())
         })
-        .context(SerializeSnafu)?;
-        conn.execute(
-            "INSERT OR REPLACE INTO snapshots (id, data) VALUES ('current', ?1)",
-            params![snapshot_blob],
-        )
-        .context(ExecuteSnafu)?;
-
-        // Commit transaction - guard is consumed and dropped after commit
-        guard.commit()?;
-
-        Ok(())
+        .await
+        .map_err(|err| join_error_to_io(err, "snapshot_install"))?
     }
 
     async fn get_current_snapshot(&mut self) -> Result<Option<Snapshot<AppTypeConfig>>, io::Error> {
