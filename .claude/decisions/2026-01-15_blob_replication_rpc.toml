# =============================================================================
# Blob Replication RPC Implementation
# =============================================================================

[metadata]
id = "ADR-2026-0017"
title = "Blob Replication Push Notification via RPC"
date = "2026-01-15"
author = "Claude (Ultra Mode)"
status = "implemented"

[classification]
type = "implementation"
category = "blob-replication"
tags = ["blob", "replication", "rpc", "iroh", "p2p"]
priority = "high"

# =============================================================================
# SUMMARY
# =============================================================================

[summary]
description = """
Implemented the missing piece of blob replication: actual P2P transfer coordination.

Previously, the blob replication system had all the infrastructure in place
(ReplicationManager, placement strategies, metadata tracking) but the actual
`transfer_to_node()` function was a stub that just returned `Ok(true)`.

This change implements the complete replication flow:
1. Source node receives BlobAdded event
2. ReplicationManager selects target nodes via WeightedPlacement
3. Source sends BlobReplicatePull RPC to each target
4. Target downloads blob from source using iroh-blobs download_from_peer()
5. Target protects blob with replica tag to prevent GC
6. Source receives success/failure response
"""

problem = "transfer_to_node() was stubbed - no actual P2P transfer happened"
solution = "Added BlobReplicatePull RPC and implemented actual iroh-based transfer"

# =============================================================================
# CHANGES
# =============================================================================

[[changes]]
file = "crates/aspen-client-api/src/messages.rs"
description = """
Added new ClientRpcRequest variants:
- BlobReplicatePull: Request target to download blob from provider
- GetBlobReplicationStatus: Query replica metadata for a blob
- TriggerBlobReplication: Manually trigger replication (placeholder)

Added corresponding ClientRpcResponse variants and response structs:
- BlobReplicatePullResultResponse
- GetBlobReplicationStatusResultResponse
- TriggerBlobReplicationResultResponse

Updated to_operation() match to include new variants for authorization.
"""

[[changes]]
file = "crates/aspen-rpc-handlers/src/handlers/blob.rs"
description = """
Added handlers for new blob replication requests:

handle_blob_replicate_pull():
- Validates hash and provider public key
- Checks if blob already exists locally (skip if so)
- Downloads blob from provider using download_from_peer()
- Applies _replica:{hash} tag to prevent GC
- Returns success/failure with duration metrics

handle_get_blob_replication_status():
- Reads replica metadata from _system:blob:replica:{hash} key
- Parses JSON to extract nodes, policy, status
- Calculates health status (critical/under_replicated/degraded/healthy)
- Returns comprehensive status response

handle_trigger_blob_replication():
- Placeholder implementation (returns error)
- Will integrate with BlobReplicationManager in future
"""

[[changes]]
file = "crates/aspen-blob/src/replication/adapters.rs"
description = """
Replaced stub transfer_to_node() with full implementation:

IrohBlobTransfer::transfer_to_node():
1. Verify blob exists locally
2. Get blob size from status
3. Get our public key as provider
4. Build BlobReplicatePull RPC request
5. Connect to target via CLIENT_ALPN
6. Send request via postcard serialization
7. Wait for response with 30s timeout
8. Parse response and return success/failure

Added dependencies:
- aspen-client-api for ClientRpcRequest/Response types
- postcard for serialization
- iroh::EndpointAddr for addressing

Updated constructor to accept Endpoint for RPC.
"""

[[changes]]
file = "crates/aspen-cluster/src/bootstrap.rs"
description = """
Updated initialize_blob_replication() signature to accept:
- endpoint: Option<iroh::Endpoint>

This enables IrohBlobTransfer to make RPC calls to target nodes.
"""

[[changes]]
file = "crates/aspen-blob/Cargo.toml"
description = """
Added dependencies:
- aspen-client-api (for RPC types)
- postcard (for serialization)
"""

# =============================================================================
# REPLICATION FLOW (Now Complete)
# =============================================================================

[replication_flow]
description = """
Complete blob replication flow (now implemented end-to-end):

1. Client adds blob to node A:
   blob_store.add_bytes(data) -> BlobAdded event

2. ReplicationManager receives BlobAdded event:
   - Checks if auto_replicate enabled
   - Creates ReplicationRequest with hash, size

3. ReplicationManager selects targets:
   - WeightedPlacement.select_targets() picks N nodes
   - Considers failure domains, capacity weights

4. For each target node B:
   - IrohBlobTransfer.transfer_to_node(hash, target_info)

5. transfer_to_node() implementation:
   a. Verify blob exists locally on A
   b. Build BlobReplicatePull { hash, size, provider: A's pubkey }
   c. Connect to B via Iroh QUIC (CLIENT_ALPN)
   d. Send request via postcard
   e. Wait for response (30s timeout)

6. Target node B receives request (handle_blob_replicate_pull):
   a. Check if blob already exists -> skip if so
   b. Call blob_store.download_from_peer(hash, provider_key)
   c. iroh-blobs downloads from A using QUIC
   d. Apply _replica:{hash} tag to prevent GC
   e. Return success response

7. ReplicationManager updates metadata:
   - Save ReplicaSet to _system:blob:replica:{hash}
   - Track which nodes have confirmed copies

8. Repair cycle (background):
   - Periodic scan for under_replicated blobs
   - Trigger additional replications as needed
"""

# =============================================================================
# API ADDITIONS
# =============================================================================

[api.blob_replicate_pull]
request = """
BlobReplicatePull {
    hash: String,        // BLAKE3 hash (hex)
    size: u64,           // Expected blob size
    provider: String,    // Provider public key
    tag: Option<String>, // Optional protection tag
}
"""
response = """
BlobReplicatePullResultResponse {
    success: bool,
    hash: Option<String>,
    size: Option<u64>,
    duration_ms: Option<u64>,
    error: Option<String>,
}
"""
purpose = "Target-side handler: download blob from provider for replication"

[api.get_blob_replication_status]
request = """
GetBlobReplicationStatus {
    hash: String,  // BLAKE3 hash (hex)
}
"""
response = """
GetBlobReplicationStatusResultResponse {
    found: bool,
    hash: Option<String>,
    size: Option<u64>,
    replica_nodes: Option<Vec<u64>>,
    replication_factor: Option<u32>,
    min_replicas: Option<u32>,
    status: Option<String>,      // critical/under_replicated/degraded/healthy
    replicas_needed: Option<u32>,
    updated_at: Option<String>,
    error: Option<String>,
}
"""
purpose = "Query replication metadata and health status for a blob"

[api.trigger_blob_replication]
request = """
TriggerBlobReplication {
    hash: String,
    target_nodes: Vec<u64>,
    replication_factor: u32,
}
"""
response = """
TriggerBlobReplicationResultResponse {
    success: bool,
    hash: Option<String>,
    successful_nodes: Option<Vec<u64>>,
    failed_nodes: Option<Vec<(u64, String)>>,
    duration_ms: Option<u64>,
    error: Option<String>,
}
"""
purpose = "Manual replication trigger (placeholder, returns error)"
status = "Not yet implemented - needs BlobReplicationManager integration"

# =============================================================================
# REMAINING WORK
# =============================================================================

[remaining_work]
items = [
    { task = "Wire cluster membership events to update_topology()", priority = "high", status = "completed" },
    { task = "Add CLI commands (blob replication-status)", priority = "medium", status = "completed" },
    { task = "Add prometheus metrics for replication", priority = "medium", status = "pending" },
    { task = "Implement TriggerBlobReplication with manager integration", priority = "low", status = "pending" },
    { task = "Integration tests with multi-node cluster", priority = "high", status = "pending" },
]

[[changes]]
file = "src/bin/aspen-node.rs"
description = """
Added blob replication initialization to node startup:
- Calls initialize_blob_replication() after bootstrap
- Wires topology watcher to Raft metrics for membership updates
- Extracts NodeInfo from membership config for placement strategy

Added accessor methods to NodeMode:
- shutdown_token() - returns shutdown cancellation token
- blob_replication_mut() - mutable access to blob replication resources
- config() - returns node configuration
"""

[[changes]]
file = "crates/aspen-cli/src/bin/aspen-cli/commands/blob.rs"
description = """
Added blob replication-status CLI command:
- ReplicationStatus subcommand for querying replication status
- ReplicationStatusArgs for command parameters
- BlobReplicationStatusOutput for formatted output
- blob_replication_status() handler using GetBlobReplicationStatus RPC
"""

# =============================================================================
# TESTING
# =============================================================================

[testing]
build_status = "Passed (cargo build)"
test_status = "All existing tests pass"
tests_run = [
    "cargo nextest run -P quick -E 'test(/blob/)' - 7 passed",
    "cargo nextest run -P quick -E 'test(/replica/)' - 5 passed",
]
integration_tests_needed = """
Multi-node cluster tests require:
1. madsim-based deterministic test with 3+ nodes
2. Add blob on node A, verify replication to nodes B and C
3. Test failure scenarios (node down during replication)
4. Test repair cycle for under-replicated blobs
5. Test topology updates when nodes join/leave
"""

[session_summary]
date = "2026-01-15"
completed = [
    "BlobReplicatePull RPC handler implementation",
    "GetBlobReplicationStatus RPC handler implementation",
    "IrohBlobTransfer.transfer_to_node() with actual RPC",
    "topology_watcher.rs for Raft membership tracking",
    "Node startup wiring for blob replication",
    "CLI command: blob replication-status",
]
deferred = [
    "Prometheus metrics (needs BlobReplicationManager in RPC context)",
    "Multi-node integration tests (complex infrastructure setup)",
    "TriggerBlobReplication implementation",
]
notes = """
The blob replication system is now functionally complete for the core use case:
1. When a blob is added, BlobReplicationManager receives the event
2. WeightedPlacement selects target nodes based on topology
3. IrohBlobTransfer sends BlobReplicatePull RPC to targets
4. Target nodes download blob via iroh-blobs and protect with replica tag
5. Topology watcher keeps placement strategy updated with Raft membership

What's missing is verification through multi-node tests and prometheus metrics.
"""

# =============================================================================
# METRICS TO ADD (Future)
# =============================================================================

[future_metrics]
counters = [
    "aspen_blob_replications_total{status=success|failure}",
    "aspen_blob_repairs_total{reason=critical|under_replicated|degraded}",
]
gauges = [
    "aspen_blob_replicas_total{hash}",
    "aspen_blob_under_replicated_count",
    "aspen_blob_repair_queue_size",
]
histograms = [
    "aspen_blob_replication_duration_seconds",
    "aspen_blob_download_duration_seconds",
]
