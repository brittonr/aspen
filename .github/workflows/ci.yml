name: CI

on:
  push:
    branches: [main]
  pull_request:
    branches: [main]

# Cancel in-progress runs for the same workflow + branch/PR combo
concurrency:
  group: ${{ github.workflow }}-${{ github.ref }}
  cancel-in-progress: true

env:
  CARGO_TERM_COLOR: always
  RUST_BACKTRACE: 1

jobs:
  format-check:
    name: Format Check
    runs-on: ubuntu-latest
    timeout-minutes: 10
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Install Nix
        uses: cachix/install-nix-action@v27
        with:
          extra_nix_config: |
            experimental-features = nix-command flakes
            accept-flake-config = true

      - name: Setup Cachix
        uses: cachix/cachix-action@v15
        with:
          name: aspen-builds
          authToken: ${{ secrets.CACHIX_AUTH_TOKEN }}

      - name: Check code formatting
        run: nix fmt -- --check .

  test:
    name: Test Suite
    runs-on: ubuntu-latest
    timeout-minutes: 30
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Install Nix
        uses: cachix/install-nix-action@v27
        with:
          extra_nix_config: |
            experimental-features = nix-command flakes
            accept-flake-config = true

      - name: Setup Cachix
        uses: cachix/cachix-action@v15
        with:
          name: aspen-builds
          authToken: ${{ secrets.CACHIX_AUTH_TOKEN }}

      - name: Run tests with JUnit output
        id: nextest
        run: |
          # Run nextest directly to capture JUnit XML for reporting
          # Skip the slow acceptance criteria test that requires .git directory
          nix develop -c cargo nextest run \
            --profile ci \
            --no-fail-fast \
            -E 'not test(=acceptance_criteria_for_upgrades)' \
            2>&1 | tee test-output.log
        continue-on-error: true

      - name: Copy JUnit results
        if: always()
        run: |
          # Copy JUnit XML to a known location for the reporter
          mkdir -p test-results
          if [ -f target/nextest/ci/junit.xml ]; then
            cp target/nextest/ci/junit.xml test-results/
          elif [ -f target/nextest/default/junit.xml ]; then
            cp target/nextest/default/junit.xml test-results/
          fi
          # Also check for junit.xml in current directory
          if [ -f junit.xml ]; then
            cp junit.xml test-results/
          fi

      - name: Upload JUnit results
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: test-results-${{ github.run_id }}
          path: test-results/
          retention-days: 7
          if-no-files-found: ignore

      - name: Test Report
        uses: dorny/test-reporter@v1
        if: always() && (github.event_name == 'pull_request' || github.ref == 'refs/heads/main')
        with:
          name: Nextest Results
          path: 'test-results/*.xml'
          reporter: java-junit
          fail-on-error: false

      - name: Generate test summary
        if: always()
        run: |
          echo "## Test Results" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          if [ -f test-results/junit.xml ]; then
            # Parse JUnit XML for summary
            TESTS=$(grep -oP 'tests="\K[0-9]+' test-results/junit.xml | head -1 || echo "0")
            FAILURES=$(grep -oP 'failures="\K[0-9]+' test-results/junit.xml | head -1 || echo "0")
            ERRORS=$(grep -oP 'errors="\K[0-9]+' test-results/junit.xml | head -1 || echo "0")
            TIME=$(grep -oP 'time="\K[0-9.]+' test-results/junit.xml | head -1 || echo "0")

            echo "| Metric | Value |" >> $GITHUB_STEP_SUMMARY
            echo "|--------|-------|" >> $GITHUB_STEP_SUMMARY
            echo "| Total Tests | $TESTS |" >> $GITHUB_STEP_SUMMARY
            echo "| Failures | $FAILURES |" >> $GITHUB_STEP_SUMMARY
            echo "| Errors | $ERRORS |" >> $GITHUB_STEP_SUMMARY
            echo "| Duration | ${TIME}s |" >> $GITHUB_STEP_SUMMARY
          else
            echo "No JUnit results found" >> $GITHUB_STEP_SUMMARY
          fi

      - name: Collect simulation artifacts on failure
        if: failure()
        run: |
          # Collect simulation artifacts if they exist
          if [ -d docs/simulations ]; then
            mkdir -p simulation-artifacts
            cp docs/simulations/*.json simulation-artifacts/ 2>/dev/null || true
            if [ -n "$(ls -A simulation-artifacts 2>/dev/null)" ]; then
              echo "Found simulation artifacts:"
              ls -lh simulation-artifacts/
            else
              echo "No simulation artifacts found"
            fi
          else
            echo "docs/simulations directory does not exist"
          fi

      - name: Upload simulation artifacts
        if: failure()
        uses: actions/upload-artifact@v4
        with:
          name: simulation-artifacts-${{ github.run_id }}
          path: simulation-artifacts/
          retention-days: ${{ github.event_name == 'pull_request' && 7 || 30 }}
          if-no-files-found: ignore

      - name: Fail if tests failed
        if: steps.nextest.outcome == 'failure'
        run: exit 1

  clippy:
    name: Clippy Lints
    runs-on: ubuntu-latest
    timeout-minutes: 15
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Install Nix
        uses: cachix/install-nix-action@v27
        with:
          extra_nix_config: |
            experimental-features = nix-command flakes
            accept-flake-config = true

      - name: Setup Cachix
        uses: cachix/cachix-action@v15
        with:
          name: aspen-builds
          authToken: ${{ secrets.CACHIX_AUTH_TOKEN }}

      - name: Run Clippy
        run: |
          nix develop -c cargo clippy --all-targets -- --deny warnings

  smoke-test:
    name: Smoke Test
    runs-on: ubuntu-latest
    timeout-minutes: 30
    needs: [test]  # Only run smoke test if unit tests pass
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Install Nix
        uses: cachix/install-nix-action@v27
        with:
          extra_nix_config: |
            experimental-features = nix-command flakes
            accept-flake-config = true

      - name: Setup Cachix
        uses: cachix/cachix-action@v15
        with:
          name: aspen-builds
          authToken: ${{ secrets.CACHIX_AUTH_TOKEN }}

      - name: Build aspen-node binary
        run: |
          # Build the aspen-node binary using Nix
          nix develop -c cargo build --bin aspen-node
          ls -lh target/debug/aspen-node

      - name: Run Raft smoke test
        id: smoke-test
        timeout-minutes: 5
        run: |
          # Run the aspen-cluster-raft-smoke.sh script
          ./scripts/aspen-cluster-raft-smoke.sh
        continue-on-error: true

      - name: Collect logs on failure
        if: failure() && steps.smoke-test.outcome == 'failure'
        run: |
          # Collect node logs if they exist
          mkdir -p smoke-test-logs
          cp n*.log smoke-test-logs/ 2>/dev/null || true
          if [ -n "$(ls -A smoke-test-logs 2>/dev/null)" ]; then
            echo "Found smoke test logs:"
            ls -lh smoke-test-logs/
          else
            echo "No smoke test logs found"
          fi

      - name: Upload smoke test logs
        if: failure() && steps.smoke-test.outcome == 'failure'
        uses: actions/upload-artifact@v4
        with:
          name: smoke-test-logs-${{ github.run_id }}
          path: smoke-test-logs/
          retention-days: 7
          if-no-files-found: ignore

      - name: Fail if smoke test failed
        if: steps.smoke-test.outcome == 'failure'
        run: exit 1

  # Summary job for branch protection rules
  ci-complete:
    name: CI Complete
    runs-on: ubuntu-latest
    needs: [format-check, test, clippy, smoke-test]
    if: always()
    steps:
      - name: Check all jobs
        run: |
          if [ "${{ needs.format-check.result }}" != "success" ]; then
            echo "Format check failed"
            exit 1
          fi
          if [ "${{ needs.test.result }}" != "success" ]; then
            echo "Tests failed"
            exit 1
          fi
          if [ "${{ needs.clippy.result }}" != "success" ]; then
            echo "Clippy failed"
            exit 1
          fi
          if [ "${{ needs.smoke-test.result }}" != "success" ]; then
            echo "Smoke test failed"
            exit 1
          fi
          echo "All CI checks passed!"
